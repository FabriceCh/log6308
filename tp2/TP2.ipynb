{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Q1: Supposons que je lis le document numéro '422908' dans ma matrice. Appliquez l'algorithme Page rank pour déterminer les autres lectures recommandées. En plus de la simple recommandation des références de '422908', appliquez au moins une variation de cette approche de base, comme celle exposée en classe qui consiste à étendre le sous-ensemble S (références) à S' (références des références). Expliquez la démarche que vous avez prise.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#can be removed\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier `citeseet.csv` est simplement la `rtable` à l'adresse `http://cours.polymtl.ca/MDesmarais/log6308/Public/citeseer.rtable`. Le code ci-dessous permet de storer les informations dans un dataframe de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"citeseer.csv\", index_col=0)\n",
    "df.columns = [int(col[1:]) for col in df.columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des données\n",
    "\n",
    "La librarie `networkx` permet de prendre le dataframe et d'en faire un objet représentant un graphe. Cela permet de manipuler plus facilement les articles.\n",
    "\n",
    "[Networkx](https://networkx.github.io/documentation/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_di = nx.from_pandas_adjacency(df, create_using=nx.DiGraph())\n",
    "nx.info(G_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_graph = False #change this to show a graph output\n",
    "if generate_graph:\n",
    "    G_no_isolates = G_di\n",
    "    G_no_isolates.remove_nodes_from(list(nx.isolates(G_di)))\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    fig.suptitle(\"graph without isolates\", fontsize=20)\n",
    "    nx.draw(G_no_isolates, with_labels=True, font_weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank\n",
    "\n",
    "La librarie permet entre autres d'[appliquer l'algorithme de PageRank](https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank_numpy.html) sur un graphe. \n",
    "Une autre fonction possible dans la librarie permet d'appliquer [une variante](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html) qui converti tous les arêtes en arête bidirectionnel, ignorant alors le sens des liens entre les articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank_numpy(G_di)\n",
    "#print some to make sure they make sense\n",
    "list(islice(pr.items(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr[422908]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction générale\n",
    "La fonction `get_top_recommendations` ci-dessous ne comporte pas directement de calcul de pagerank. Elle ne fait que prendre un article, un graphe, et un dictionnaire `key=article value=pagerank_score` afin de redonner les recommandations selon le nombre de recommandations et le niveau d'ensembles voulus.\n",
    "\n",
    "Par exemple, `max_deepness=1` indique que l'on veut se limiter à S et `max_deepness=2` indique que l'on veut également considérer les articles se trouvant dans l'ensemble S'. \n",
    "\n",
    "`graph.neighbors(n)` [retourne tous les noeuds m où il existe une arête de n qui pointe vers m](https://networkx.github.io/documentation/stable/reference/classes/generated/networkx.DiGraph.neighbors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations_pagerank(page_ranks, graph, article, n_recommendations=10, max_deepness=1):\n",
    "    possible_article_recommendations = []\n",
    "    last_discovered_nodes = [article]\n",
    "    deepness_reached = 0\n",
    "    while deepness_reached <= max_deepness:\n",
    "        new_discovered_nodes = []\n",
    "        for discovered_node in last_discovered_nodes:\n",
    "            for neighbor in graph.neighbors(discovered_node):\n",
    "                new_discovered_nodes.append(neighbor)\n",
    "                if neighbor not in possible_article_recommendations and neighbor != article:\n",
    "                    possible_article_recommendations.append(neighbor)\n",
    "        last_discovered_nodes = new_discovered_nodes\n",
    "        deepness_reached += 1\n",
    "    pr_neighbors = {article_key:page_ranks[article_key] for article_key in possible_article_recommendations}\n",
    "    return sorted(pr_neighbors, key=pr_neighbors.get, reverse=True)[:n_recommendations] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations à l'approche Pagerank de base\n",
    "D'abord, nous allons tenter l'expérience avec S' au lieu de S seulement. \n",
    "\n",
    "De plus, nous allons tenter une autre approche, qui est de considérer un graphe non-orienté. Nous justifions l'essai de cette alternative en supposant que les articles peuvent être tout autant pertinents même s'il ne sont pas référencés par l'article de départ, en autant qu'ils référencient celui-ci. Autrement dit, selon cette approche, que ce soit n->m ou m->n, l'important est simplement qu'il y ait un lien entre ces articles, le sens n'a plus ou moins d'importance.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats\n",
    "Les résultats suivants représentent les recommandations d'articles pour S et S' ainsi que S et S' pour une variante de l'algorithme de pagerank qui considère tous les arêtes du graphe comme bidirectionnelles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = 422908\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S\n",
    "results[\"Pagerank S\"] = get_top_recommendations_pagerank(pr, G_di, document)\n",
    "print(results[\"Pagerank S\"])\n",
    "\n",
    "# S'\n",
    "results[\"Pagerank S\\'\"] = get_top_recommendations_pagerank(pr, G_di, document, max_deepness=2)\n",
    "print(results[\"Pagerank S\\'\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les résultats sont identiques pour les 5 premières recommendations. Par contre, à la sixième recommendation, les deux approches divergent avec S' qui contient un article avec un score pagerank assez élevé pour faire partie des recommendations (61863) que S ne contient pas.\n",
    "\n",
    "L'expérience qui suit présente une autre approche, qui est d'appliquer [pagerank en ignorant la direction des arêtes](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html) entre les articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_undi = nx.from_pandas_adjacency(df) # creates an undirected graph\n",
    "pr = nx.pagerank(G_undi)\n",
    "\n",
    "# S\n",
    "results[\"pr undirected S\"] = get_top_recommendations_pagerank(pr, G_undi, document)\n",
    "print(results[\"pr undirected S\"])\n",
    "\n",
    "# S'\n",
    "results[\"pr undirected S\\'\"] = get_top_recommendations_pagerank(pr, G_undi, document, max_deepness=2)\n",
    "print(results[\"pr undirected S\\'\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'avec cette approche, les articles recommandés diffèrent de l'aproche de base après les deux premiers, et que de nouveaux articles font surface (38085, 245669, 164643, 547939, 220337, 500980, 371548, 368281, 83263)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "TODO: discuter de la qualité des résultats (quand l'API du prof va marcher) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Q2: Comparez les résultats obtenus avec une approche basée sur la similarité des articles dans un espace vectoriel, à l'instar du calcul de similarité de l'approche item-item. La mesure de la similarité et la façon de l'utiliser pour estimer la pertinence d'articles similaires est laissé à votre discrétion.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idéal serait de comparer les descriptions entre elles avec du NLP afin de déterminer un score de similarité entre l'article 422908 et chacun des autres articles. \n",
    "\n",
    "Par contre, l'approche que nous allons utiliser ici est de comparer les vecteurs de références d'articles et appliquer le cosinus afin de recommander des articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations_cosine(dataframe, article, n_recommendations=10):\n",
    "    df_cos = dataframe.copy()\n",
    "    df_cos[:] = cosine_similarity(df_cos)\n",
    "    df_cos = df_cos.sort_values(by=article, ascending=False)\n",
    "    return list(df_cos[1:n_recommendations + 1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats et comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"cosine item-item\"] = get_top_recommendations_cosine(df, document)\n",
    "for key in results.keys():\n",
    "    print(\"      \" + key + \"\\t\" + str(results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "On peut constater que les recommandations selon l'approche item-item avec le cosinus présente des résultats assez différents des deux approches précédentes. La plupart des articles recommandés n'étaient pas présents dans les recommandations de Pagerank. Par contre, on y retrouve des articles qui avaient déjà été détectés par Pagerank: 70445, 155792 et 17094.\n",
    "\n",
    "On peut donc confirmer que les deux approches semblent bien fonctionner à leur façon, et donnent des résultats plutôt différents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Q3:  Utilisez une validation croisée pour évaluer la performance de l'approche item-item.__ Vous pouvez vous inspirer de l'approche utilisée dans l'article suivant pour la méthodologie à adopter:\n",
    "McNee, S. M., Albert, I., Cosley, D., Gopalkrishnan, P., Lam, S. K., Rashid, A., Konstan, J. A., and Riedl, J. 2002. On the recommending of citations for research papers. In Proceedings of the 2002 ACM Conference on Computer Supported Cooperative Work (New Orleans, Louisiana, USA, November 16 - 20, 2002). CSCW '02. ACM, New York, NY, 116-125. DOI=http://doi.acm.org/10.1145/587078.587096\n",
    "# Cependant, vous pouvez aussi adapter cette méthodologie ou en définir une différente. Par exemple, les \"observations\" que l'on peut vraisemblablement considérer comme valables pour les tests sont les références d'ordre 1 et 2 de la matrice d'adjacence et de sa transposée. Compte tenu du faible nombre de références, il est préférable d'adopter une approche \"leave one out\", où une seule \"observation\" est retirée du corpus à la fois, et où l'on compare une mesure du degré de confiance à prédire cette observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
